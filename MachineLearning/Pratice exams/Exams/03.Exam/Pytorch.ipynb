{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b0a572",
   "metadata": {},
   "source": [
    "## Aula Assíncrona 22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee804a1f",
   "metadata": {},
   "source": [
    "- RA: 23022371 - Carlos Eduardo de Souza\n",
    "- RA: 23022369 - Bruno Caboclo Dos Santos Ribeiro\n",
    "- RA: 23022385 - Julia Correa Colombo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23cb957b",
   "metadata": {},
   "source": [
    "# Título: Classificação de popularidade de músicas usando PyTorch\n",
    "\n",
    "## Descrição:\n",
    "Neste exercício, você será desafiado a aplicar o PyTorch para construir um modelo de classificação capaz de prever a popularidade de músicas com base em seus recursos. Para isso, utilizaremos um conjunto de dados que contém informações sobre as melhores músicas do Spotify de 2000 a 2023.\n",
    "\n",
    "### O conjunto de dados possui as seguintes colunas relevantes para nosso problema:\n",
    "\n",
    "- artist: o artista da música\n",
    "- top genre: o gênero musical predominante da música\n",
    "- bpm: batidas por minuto da música\n",
    "- energy: energia da música\n",
    "- dB: decibéis da música\n",
    "- liveness: probabilidade de ser uma gravação ao vivo\n",
    "- valence: valência emocional da música\n",
    "- acousticness: probabilidade de ser uma música acústica\n",
    "- danceability: capacidade de dançar ao ritmo da música\n",
    "- duration: duração da música em segundos\n",
    "- speechiness: probabilidade de conter palavras faladas na música\n",
    "- popularity: popularidade da música (variando de 0 a 100)\n",
    "\n",
    "\n",
    "Seu objetivo é treinar um modelo de classificação usando PyTorch que seja capaz de prever a popularidade de uma música com base em seus recursos.\n",
    "\n",
    "### Sugestão de passos a seguir:\n",
    "\n",
    "1. Faça a importação do conjunto de dados a partir do dataset fornecido.\n",
    "2. Importe as bibliotecas necessárias: pandas, numpy, torch, torchvision, etc.\n",
    "3. Carregue o conjunto de dados usando a biblioteca Pandas.\n",
    "4. Realize o pré-processamento necessário no conjunto de dados, incluindo a categorização dos valores da coluna \"popularity\" em três classes (0, 1 e 2) usando a função pd.cut.\n",
    "5. Realize a codificação one-hot das colunas \"artist\" e \"top genre\" usando a função onehot_encode.\n",
    "6. Separe o conjunto de dados em recursos (X) e rótulos de destino (y). Descarte as colunas irrelevantes para o modelo.\n",
    "7. Converta os dados para tensores do PyTorch.\n",
    "8. Crie uma classe CTDataset que herda torch.utils.data.Dataset e implemente os métodos __init__, __len__ e __getitem__ para representar o conjunto de dados.\n",
    "7. Divida o conjunto de dados em conjuntos de treinamento, validação e teste usando a função random_split do PyTorch, de acordo com as proporções especificadas.\n",
    "8. Crie carregadores de dados (DataLoader) para cada conjunto, com um tamanho de lote (batch size) adequado.\n",
    "9. Defina a arquitetura da rede neural no PyTorch, incluindo as camadas Linear necessárias.\n",
    "10. Defina a função de perda (loss function) como CrossEntropyLoss e o otimizador como Adam.\n",
    "11. Mova o modelo para a GPU, se disponível, para acelerar o treinamento.\n",
    "12. Execute o treinamento do modelo por um número específico de épocas, calculando a perda média ao longo das iterações de treinamento.\n",
    "13. Avalie o desempenho do modelo nos conjuntos de validação e teste, calculando a acurácia, precisão, recall e exibindo o relatório de classificação.\n",
    "15. Discuta as descobertas e faça uma reflexão sobre a aplicação do PyTorch em problemas de classificação de dados do mundo real.\n",
    "\n",
    "**O objetivo é alcançar a melhor precisão possível na classificação da popularidade das músicas. Experimente diferentes arquiteturas de rede neural, funções de ativação, hiperparâmetros e técnicas de regularização para obter resultados ainda melhores.**\n",
    "\n",
    "**Você pode utilizar as bibliotecas matplotlib ou outras ferramentas de visualização para analisar os resultados e apresentar gráficos informativos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af067c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>dB</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>118</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid - Twin Ver.</td>\n",
       "      <td>FIFTY FIFTY</td>\n",
       "      <td>k-pop girl group</td>\n",
       "      <td>2023</td>\n",
       "      <td>120</td>\n",
       "      <td>59</td>\n",
       "      <td>78</td>\n",
       "      <td>-8</td>\n",
       "      <td>35</td>\n",
       "      <td>73</td>\n",
       "      <td>174</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BESO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>95</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>-7</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>195</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy's a liar Pt. 2</td>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>bronx drill</td>\n",
       "      <td>2023</td>\n",
       "      <td>133</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>-8</td>\n",
       "      <td>25</td>\n",
       "      <td>86</td>\n",
       "      <td>131</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creepin' (with The Weeknd &amp; 21 Savage)</td>\n",
       "      <td>Metro Boomin</td>\n",
       "      <td>rap</td>\n",
       "      <td>2022</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>-6</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title          artist         top genre  \\\n",
       "0                                 Flowers     Miley Cyrus               pop   \n",
       "1                       Cupid - Twin Ver.     FIFTY FIFTY  k-pop girl group   \n",
       "2                                    BESO         ROSALÍA               pop   \n",
       "3                      Boy's a liar Pt. 2  PinkPantheress       bronx drill   \n",
       "4  Creepin' (with The Weeknd & 21 Savage)    Metro Boomin               rap   \n",
       "\n",
       "   year  bpm  energy  danceability   dB  liveness  valence  duration  \\\n",
       "0  2023  118      68             71  -4         3       65       200   \n",
       "1  2023  120      59             78  -8        35       73       174   \n",
       "2  2023   95      64             77  -7        17       53       195   \n",
       "3  2023  133      81             70  -8        25       86       131   \n",
       "4  2022   98      62             72  -6         8       17       222   \n",
       "\n",
       "   acousticness  speechiness   popularity  \n",
       "0             6             7          98  \n",
       "1            44             3          97  \n",
       "2            74            14          96  \n",
       "3            25             5          96  \n",
       "4            42             5          96  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Importação do conjunto de dados\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('./Best Songs on Spotify from 2000-2023-1.csv', delimiter=';')\n",
    "df.head()\n",
    "\n",
    "#2.Importação das bibliotecas necessárias (Já realizadas)\n",
    "\n",
    "#3.Carregamento do conjunto de dados usando a biblioteca Pandas (Já realizadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6716722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Pré-processamento do conjunto de dados\n",
    "df[\"popularity\"] = pd.cut(df[\"popularity\"], bins=[-1, 33, 66, 100], labels=[0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6d6b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cadu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Passo 5: Codificação one-hot das colunas \"artist\" e \"top genre\"\n",
    "columns_to_encode = [\"artist\", \"top genre\"]\n",
    "\n",
    "# Criar um objeto OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, sparse_output=False)\n",
    "\n",
    "# Codificar as colunas \"artist\" e \"top genre\" nos dados\n",
    "X_encoded = encoder.fit_transform(df[columns_to_encode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7550dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 6: Separação do conjunto de dados em recursos (X) e rótulos de destino (y)\n",
    "X = X_encoded.astype(float)\n",
    "y = df[\"popularity\"].values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebe4b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 7: Conversão dos dados para tensores do PyTorch\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "x_train_tensor = torch.from_numpy(X).float()\n",
    "y_train_tensor = torch.from_numpy(y).unsqueeze(1).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42a6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.Criação da classe CTDataset\n",
    "class CTDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "#7.Divisão do conjunto de dados em conjuntos de treinamento, validação e teste\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "#8.Crie carregadores de dados (DataLoader) para cada conjunto, com um tamanho de lote (batch size) adequado.\n",
    "batch_size = 64\n",
    "train_dataset = CTDataset(X_train, y_train)\n",
    "val_dataset = CTDataset(X_val, y_val)\n",
    "test_dataset = CTDataset(X_test, y_test)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879e2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.Defina a arquitetura da rede neural no PyTorch, incluindo as camadas Linear necessárias.\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1280, 256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.dropout(F.relu(self.fc1(x))) \n",
    "        x = self.dropout(F.relu(self.fc2(x)))   \n",
    "        x = self.dropout(F.relu(self.fc3(x)))  \n",
    "        x = F.log_softmax(self.fc4(x))   \n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580e64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.  Defina a função de perda (loss function) como CrossEntropyLoss e o otimizador como Adam.\n",
    "\n",
    "# Definição da arquitetura da rede neural\n",
    "model = Classifier()\n",
    "\n",
    "# Definição da função de perda (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definição do otimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "val_loss_min = np.inf\n",
    "epochs = 40\n",
    "steps = 0\n",
    "model.train()\n",
    "train_losses = []\n",
    "val_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b9f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.Mova o modelo para a GPU, se disponível, para acelerar o treinamento.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "x_train_tensor = x_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bedbb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cadu\\AppData\\Local\\Temp\\ipykernel_10312\\312785182.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.fc4(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10000/100000], Loss: 0.2028\n",
      "Epoch [20000/100000], Loss: 0.2224\n",
      "Epoch [30000/100000], Loss: 0.2604\n",
      "Epoch [40000/100000], Loss: 0.0816\n",
      "Epoch [50000/100000], Loss: 0.0487\n",
      "Epoch [60000/100000], Loss: 0.0483\n",
      "Epoch [70000/100000], Loss: 0.3402\n",
      "Epoch [80000/100000], Loss: 0.2819\n",
      "Epoch [90000/100000], Loss: 0.0639\n",
      "Epoch [100000/100000], Loss: 0.2141\n"
     ]
    }
   ],
   "source": [
    "#12. Execute o treinamento do modelo por um número específico de épocas, calculando a perda média ao longo das iterações de treinamento.\n",
    "\n",
    "num_epochs = 100000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    # Printar a perda a cada 100 iterações\n",
    "    if (epoch+1) % 10000 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549e7074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de validação: 0.7067\n",
      "Acurácia no conjunto de teste: 0.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cadu\\AppData\\Local\\Temp\\ipykernel_10312\\312785182.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.fc4(x))\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "val_accuracy = evaluate(model, val_loader)\n",
    "print(f\"Acurácia no conjunto de validação: {val_accuracy:.4f}\")\n",
    "\n",
    "# Avaliação no conjunto de teste\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Acurácia no conjunto de teste: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c291a467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEYCAYAAABbd527AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvW0lEQVR4nO3deXhU5dnH8e9NFrIACQn7EhJkSdiXiIh1A1RUcKtWcae2tLaVqrW+amuJa32VuluUKu5rLfqGVVHEpYIKyJYFCHvYEgJZyZ77/WMGGCJLgMyczMz9ua65ZubMmZl7TjK/c+Y55zmPqCrGGGOCRzOnCzDGGONbFvzGGBNkLPiNMSbIWPAbY0yQseA3xpggY8FvjDFBxoLf+B0RmSMit9abdrmIbBWRUhEZLCIZInKOl+t4TUQe9uZ7nAgR2SQio52uwzRdFvzG50TkGhH5TkTKRCTPfft3IiINeO6NwB5VnVrvoSnAH1S1har+qKp9VXWhN+pvDCKi7s9fKiLbRORJEQlxui4THCz4jU+JyJ+AZ4AngA5Ae+C3wBlA+BGe4xmILYDfHGa2bkBGoxbrfQNVtQUwCrgW+PXxPFlEQr1SlQl4FvzGZ0QkBngQ+J2qfqiqJeryo6pep6qV7vleE5Gp7iadMuBcEblYRH4EHgOyRSTNPW9zESkFQoAVIrLePf1Ac4eIhIjIfSKyXkRKRGSpiHR1PzZCRH4QkSL39Yij1D9YRJa5X+N9IKLe42NFZLmIFIrItyIyoCHLRVWzga+Bfsd6Hffn+h8RWQmUiUioiNwgIptFpEBE/lKvpmEissj9WjtE5HkRCXc/JiLylPtXV7GIrBKRfg2p2fg5VbWLXXxyAcYANUDoMeZ7DSjC9SugGa6AHQn0d98fAOQBl3k8R4EeHvc3AaPdt/8MrAJ6AwIMBOKBOGAvcAMQCox3348/TE3hwGbgDiAMuBKoBh52Pz7YXdNpuFZCN7lraH6Ez3igXqAPsBO45Viv4769HOgKRLqfWwqcBTQHnnQv4/2ffSgw3P35EoEs4Hb3YxcAS4FY93JJATo6/X9iF+9fbIvf+FIbYLeq1uyf4N6iLRSRchE5y2Pe/1PV/6pqnapWqOoCVV3lvr8SeAc4u4Hv+yvgr6q6Rl1WqGoBcDGwTlXfVNUaVX0XyAbGHeY1huMK/KdVtVpVPwR+8Hh8IvCSqn6nqrWq+jpQ6X7ekSwTkb3ATOBl4NUGvs6zqrpVVctxrYBmqepX6vrFdD9Qt39GVV2qqovdn28T8JLHcqsGWgLJgKhqlqruOMayNAHA2giNLxUAbUQkdH/4q+oIABHJ5dCmx62eTxSRIcAjuLZKBYjBFZgN0RVYf5jpnXBtxXvaDHQ+wrzbVFXrzbtfN+AmEbnNY1q4+3lHMkRVczwniEhDXsdz2XTyvK+qZSJS4PF6vXD9CkgFonB955e6510gIs8DLwDdRGQGcJeqFh+lZhMAbIvf+NIiXFuvlzZg3vqnjX0fmIWreaQb8DquFUBDbAVOOcz07bgC21MCsO0w8+4AOtc78iih3ns8oqqxHpco96+I49GQ1/FcNjtwrdgAEJEoXM1Y+03F9Sump6q2Au7DY7mp6rOqOhRXk1EvXM1iJsBZ8BufUdVC4AHgnyJypYi0FJFmIjIIiD7G02OBclWtEZFhuNrjG+pl4CER6eneoTlAROKBOUAvEbnWvZP0alwBOOswr7EIV9v5JBEJE5ErgGEej/8L+K2InOZ+j2j3DumWx1HnibzOh8BYEfmZe6ftgxz6vW4JFAOlIpIMHOj/ICKnut8nDCgDKvBoJjKBy4Lf+JSqPg7cCdwN7HJfXgL+B/j2KE+9FZgsIiXA34APjuNtn3TP/ymuEHwFiHS3848F/oSrGepuYKyq7j5M3VXAFcDNwB7gamCGx+NLcB2O+TyuHcQ57nmPy/G+jqpmAL/Htc9jh/s5uR6z3IXrUNESXCuV9z0ea+WethdXs1UBrsNsTYCTQ5ssjTHGBDrb4jfGmCBjwW+MMUHGgt8YY4KMBb8xxgQZv+jA1aZNG01MTHS6DGOM8StLly7drapt60/3i+BPTExkyZIlTpdhjDF+RUTq90wHrKnHGGOCjgW/McYEGQt+Y4wJMn7Rxn841dXV5ObmUlFR4XQpjomIiKBLly6EhYU5XYoxxo/4bfDn5ubSsmVLEhMTkWMP1RpwVJWCggJyc3NJSkpyuhxjjB/xWlOPiEx3D+m22mNanIjMF5F17uvWJ/r6FRUVxMfHB2XoA4gI8fHxQf2LxxhzYrzZxv8arqH2PN0DfK6qPYHP3fdPWLCG/n7B/vmNMSfGa8Gvql/hOn2tp0txDaCB+/oyb72/Mcb4sy0F+3hwZiY1tY0/RIKvj+pp7zGm506g/ZFmFJGJIrJERJbk5+f7proTUFdXx5gxY9iyZYvTpRhjAkB5VS1PfrqG0U99ybvfbyFrR0mjv4djO3dVVUXkiIMBqOo0YBpAampqkx00YOPGjdx7770kJCQce2ZjjDkCVWX2qh08OjuL7UUVXDqoE/dcmEzHmMhGfy9fB/8uEemoqjtEpCOQ5+P3b1QhISH079//wP1rrrmGe+45qd0WxpgglL2zmLT0DBZv2ENKx1Y8fc1ghiXFee39fB386cBNwGPu6//z8fs3qsjISJYvX+50GcYYP1W4r4qn5q/lzcWbaRUZxsOX9WP8sARCmnn3wA1vHs75Lq4BqnuLSK6I3IIr8M8TkXXAaPf9gJOYmMjdd99N//79GTZsGDk5OQBs2rSJkSNHMmDAAEaNGnVgv8CuXbu4/PLLGThwIAMHDuTbb11Dz1522WUMHTqUvn37Mm3aNMc+jzGmcdXWKe98t4VzpyzkzcWbue60biy86xyuH97N66EPXtziV9XxR3hoVGO/1wMzM8jcXtyor9mnUysmj+t71HnKy8sZNGjQgfv33nsvV199NQAxMTGsWrWKN954g9tvv51Zs2Zx2223cdNNN3HTTTcxffp0Jk2axMcff8ykSZM4++yz+eijj6itraW0tBSA6dOnExcXR3l5Oaeeeio///nPiY+Pb9TPaYzxraWb9zA5PYPV24oZlhRH2ri+9OnUyqc1+G3P3abgaE0948ePP3B9xx13ALBo0SJmzJgBwA033MDdd98NwIIFC3jjjTcA136DmJgYAJ599lk++ugjALZu3cq6dess+I3xU7uKK3hsbjYf/biNDq0ieHb8YMYN6OhIf5yACP5jbZk7wfOPeSJ/2IULF/LZZ5+xaNEioqKiOOecc6yXrjF+qLKmllf/u4nnPl9Hda3y+3NP4ffn9iAq3Ln4tbNzesn7779/4Pr0008HYMSIEbz33nsAvP3225x55pkAjBo1iqlTpwJQW1tLUVERRUVFtG7dmqioKLKzs1m8eLEDn8IYczK+WJPHmKe/5rG52Zx+Sjzz7zyLP1+Q7GjoQ4Bs8Tulfhv/mDFjeOwx1/7qvXv3MmDAAJo3b867774LwHPPPceECRN44oknaNu2La+++ioAzzzzDBMnTuSVV14hJCSEqVOnMmbMGF588UVSUlLo3bs3w4cP9/nnM8acmE27y3hoViafZ+fRvU00r044lXN7t3O6rANEtcn2jTogNTVV6w+9mJWVRUpKikMVHd3+oSLbtGnj9fdqysvBmGBTVlnD81/k8MrXGwkLESaN6smEM5IID3WmcUVElqpqav3ptsVvjDEnSVVJX7GdR+dksau4kiuGdOaeMcm0axXhdGmHZcHvBZs2bXK6BGOMj2RsLyItPYMfNu2lf+cY/nndUIZ2O+EzzvuEBb8xxpyAvWVV/GP+Gt75bguxUeE8dkV/rkrt6pMOWCfLgt8YY46Dq9ftZqZ8upbSyhpuPD2RO0b3IibKf4ZAteA3xpgG+m5DAWkzM8naUczp3eNJu6QvvTu0dLqs42bBb4wxx7CjqJxH52Qzc8V2OsdG8s/rhnBhvw5+OwqedeA6CSEhIQwaNIh+/fpx1VVXsW/fvhN+rXPOOYf6h6waY5xVUV3LC1/kMHLKl3ySsZNJo3ry2Z1nc1F/Z0610Fgs+E/C/nP1rF69mvDwcF588cUGPa+mpsbLlRljToaqMj9zF+c/9RVPfLKGs3u15fM7z+bO83oRGR7idHknzZp6GsmZZ57JypUrKSsr47bbbmP16tVUV1eTlpbGpZdeymuvvcaMGTMoLS2ltraWefPmMWHCBFasWEFycjLl5eUHXuvWW2/lhx9+oLy8nCuvvJIHHnjAwU9mTHBZn1/KgzMz+XJtPj3ateDNW4ZxZs+2TpfVqAIj+OfeAztXNe5rdugPFzZsuICamhrmzp3LmDFjeOSRRxg5ciTTp0+nsLCQYcOGMXr0aACWLVvGypUriYuL48knnyQqKoqsrCxWrlzJkCFDDrzeI488QlxcHLW1tYwaNYqVK1cyYMCAxv18xphDlFRU8/yCHKb/dyMRoSH89eIUbhqRSFhI4DWMBEbwO8TzXD1nnnkmt9xyCyNGjCA9PZ0pU6YAUFFRcWDAlfPOO4+4ONdwal999RWTJk0CYMCAAYcE+wcffMC0adOoqalhx44dZGZmWvAb4yV1dcrHy7fx97nZ5JdU8ovULvz5gmTatmzudGleExjB38At88Z2uPPxqyr/+c9/6N279yHTv/vuO6Kjo4/5mhs3bmTKlCn88MMPtG7dmptvvtlOx2yMl6zKLWJy+mqWbSlkYNdY/nVjKoO6xjpdltcF3m8Yh11wwQU899xz7D/53Y8//njY+c466yzeeecdAFavXs3KlSsBKC4uJjo6mpiYGHbt2sXcuXN9U7gxQaSgtJJ7Z6zkkhe+YcuefTxx5QA+unVEUIQ+BMoWfxNy//33c/vttzNgwADq6upISkpi1qxZP5nv1ltvZcKECaSkpJCSksLQoUMBGDhwIIMHDyY5OZmuXbtyxhln+PojGBOwamrreHPxZp6cv5byqlpuOSOJSaN70irCf3rdNgY7LbOfs+VgTMN8u343aekZrN1Vypk92zB5XB96tPO/XrfHw07LbIwJStsKy3l0dhazV+2gS+tIXrphKOf3ae/XHbBOlgW/MSYgVVTX8tKXG5j6ZQ4Ad57Xi4lndScizP87YJ0svw5+VQ3qtbY/NNMZ42uqyicZu3h4dia5e8u5eEBH7rsohc6xkU6X1mT4bfBHRERQUFBAfHx8UIa/qlJQUEBERNMc4ccYJ+TklZCWnsk3Obvp3b4l7/z6NEac4v0hUP2N3wZ/ly5dyM3NJT8/3+lSHBMREUGXLl2cLsMYxxVXVPPMZ+t4/dtNRIWH8MAlfbnutARCA7DXbWPw2+APCwsjKSnJ6TKMMQ6qq1M+XJbL4/OyKSir4ppTE7jr/F7EtwjcXreNwW+D3xgT3JZvLWRyegYrthYyJCGWV28eRv8uMU6X5Rcs+I0xfiW/pJLH52Xz76W5tGvZnKeuHshlgzoH5b6+E2XBb4zxC9W1dbz+7Sae+WwdFTW1/Obs7tw2sictmluMHS9bYsaYJu/rdfk8MDOTnLxSzundlr+N7UP3ti2cLstvWfAbY5qsrXv28fDsTD7J2EW3+CheuSmVkcntrFnnJDkS/CJyB/ArQIFVwARVtXMPG2MAKK+qZerCHF78agMhIvz5gt786swkmodar9vG4PPgF5HOwCSgj6qWi8gHwDXAa76uxRjTtKgqc1bt5JHZmWwvquDSQZ2458JkOsZYr9vG5FRTTygQKSLVQBSw3aE6jDFNxJqdJaSlZ7BoQwEpHVvx9DWDGZYU53RZAcnnwa+q20RkCrAFKAc+VdVP688nIhOBiQAJCQm+LdIY4zNF+6p56rO1vLl4My0jQnnosn5cOyyBkGbWju8tTjT1tAYuBZKAQuDfInK9qr7lOZ+qTgOmget8/L6u0xjjXbV1ygdLtvLEJ2so3FfFdad1487zetE6Otzp0gKeE009o4GNqpoPICIzgBHAW0d9ljEmYCzdvIe09ExWbStiWGIcky/pQ99O1uvWV5wI/i3AcBGJwtXUMwpYcvSnGGMCQV5xBY/NzWbGj9vo0CqCZ8cPZtyAjnZ4po850cb/nYh8CCwDaoAfcTfpGGMCU1VNHa/+dyPPfr6O6lrl9+eewu/O6UG09bp1hCNLXVUnA5OdeG9jjG8tXJPHgzMz2bC7jNEp7bh/bB+6xUc7XVZQs9WtMcYrNu0u4+HZmXyWlUf3NtG8OuFUzu3dzumyDBb8xphGVlZZwz8X5vCvrzYSFiLce2EyE85IIjzUBkVpKiz4jTGNQlVJX7Gdv8/JZmdxBVcM7sw9FybTrpUND9rUWPAbY05a5vZi0tIz+H7THvp1bsUL1w1maDfrddtUWfAbY07Y3rIqnpy/lre/20xsVDh/v6I/v0jtar1umzgLfmPMcautU975fgv/+HQNJRU13Hh6IneM7kVMVJjTpZkGsOA3xhyX7zfuYXJ6Blk7ihnePY60S/qS3KGV02WZ42DBb4xpkJ1FFTw6J4v0FdvpFBPBC9cO4aL+HazXrR+y4DfGHFVlTS0vf72RF77IoaZOmTSqJ7eefQqR4TYoir+y4DfGHNHnWbt4cFYmmwv2cUHf9vz14j50jYtyuixzkiz4jTE/sSG/lIdmZfLFmnx6tGvBm7cM48yebZ0uyzQSC35jzAGllTU8t2Ad07/ZSERoCH+9OIWbRiQSFmK9bgOJBb8xBlXl4+Xb+PucbPJKKrlqaBf+PKY37Vpar9tAZMFvTJBbva2IyekZLN28l4FdYnjphqEMTmjtdFnGiyz4jQlSBaWVTPl0Le/9sIX46HAe//kArhzahWbW6zbgWfAbE2Rqaut4a/Fmnpy/ln1VtfzyjCT+OLonrSKs122wsOA3JogsWl/AAzMzyN5Zws96tGHyuD70bN/S6bKMj1nwGxMEthWW8+icLGav3EGX1pG8eP1QLujb3nrdBikLfmMCWEV1LdO+2sA/F+agCneM7sVvzu5ORJj1ug1mFvzGBCBV5dPMXTw8O5Ote8q5qH8H7rsohS6trdetseA3JuDk5JXwwMxMvl63m17tW/DOr05jRI82TpdlmhALfmMCRHFFNc9+to7Xvt1EVHgIaeP6cP3wboRar1tTjwW/MX6urk75z7Jc/nfeGgrKKrnm1K7cdX5v4ls0d7o000RZ8Bvjx1ZsLWRyegbLtxYyOCGW6TenMqBLrNNlmSbOgt8YP5RfUskTn2TzwZJc2rZszj+uGsjlgztbr1vTIBb8xviR6to63li0mafnr6WippbfnNWdP4zsQUvrdWuOgwW/MX7im3W7SZuZQU5eKWf1asvkcX04pW0Lp8syfsiC35gmbuuefTwyO4t5GTtJiIvi5RtTGZXSznrdmhNmwW9ME1VeVcvUL9fz0pfraSbCny/ozS0/S7Jet+akWfAb08SoKnNX7+SR2VlsKyxn3MBO3HdRMh1jIp0uzQQIC35jmpA1O0t4YGYG364vILlDS96fOJzTusc7XZYJMI4Ev4jEAi8D/QAFfqmqi5yoxZimoKi8mqfmr+XNxZtp0TyUhy7ty/hhCdbr1niFU1v8zwDzVPVKEQkH7MxRJijV1in/XrKVxz9Zw959VVw7LIG7zu9N6+hwp0szAcznwS8iMcBZwM0AqloFVPm6DmOctnTzXtLSM1i1rYhTE1szedww+nWOcbosEwSc2OJPAvKBV0VkILAU+KOqlnnOJCITgYkACQkJPi/SGG/JK67gsXnZzFi2jfatmvPMNYO4ZGAnOzzT+Iyoqm/fUCQVWAycoarficgzQLGq3n+k56SmpuqSJUt8VqMx3lBVU8dr327k2c9zqKqp45Yzk/jDuT2Ibm7HWBjvEJGlqppaf7oT/3G5QK6qfue+/yFwjwN1GOMzC9fk8eDMTDbsLmNUcjv+OrYPSW2inS7LBCmfB7+q7hSRrSLSW1XXAKOATF/XYYwvbC4o46FZWXyWtYukNtG8evOpnJvczumyTJBz6jfmbcDb7iN6NgATHKrDGK/YV1XDC1/k8K+vNhIWItxzYTITzkikeaj1ujXOcyT4VXU58JN2J2P8naoyc+UO/j4nix1FFVw+uDP3XJhM+1YRTpdmzAG2V8mYRpK5vZi0mRl8v3EPfTu14rnxg0lNjHO6LGN+woLfmJNUuK+Kf3y6lre/20xMZBiPXt6fq0/tSogNimKaqAYHv4j0A/oAB36zquob3ijKGH9QW6e8+/0Wpny6huLyam48PZE7RvciJsoGRTFNW4OCX0QmA+fgCv45wIXAN4AFvwlKP2zaw+T/yyBzRzGnJcXxwKV9Se7QyumyjGmQhm7xXwkMBH5U1Qki0h54y3tlGdM07Syq4LG5WXy8fDsdYyJ4/trBXNy/o/W6NX6locFfrqp1IlIjIq2APKCrF+sypkmprKnllW828vyCHGrqlNtG9uDWc04hKtx2kxn/09D/2iXuUyn/C9e5dUoBO42yCQoLsnfx4MxMNhXs4/w+7fnrxX1IiLcTyhr/1aDgV9XfuW++KCLzgFaqutJ7ZRnjvA35pTw0K5Mv1uTTvW00b/xyGGf1aut0WcactKMGv4gMOdpjqrqs8UsyxlmllTU8vyCHV77ZQPPQEP56cQo3np5IeKgNimICw7G2+P/hvo7A1dN2BSDAAGAJcLr3SjPGt1SV/1u+nUfnZJFXUsmVQ7tw95jetGtpvW5NYDlq8KvquQAiMgMYoqqr3Pf7AWler84YH1m9rYi09AyWbN7LwC4xvHTDUAYntHa6LGO8oqE7d3vvD30AVV0tIileqskYn9lTVsWUT9fw7vdbiIsK5/GfD+DKoV1oZr1uTQBraPCvEpGXOXjs/nWA7dw1fqumto53vt/CPz5dS2llDRNGJPHH0T2JibRetybwNTT4bwZuBf7ovv8VMNUbBRnjbYvWF/DAzAyyd5ZwRo940sb1pWf7lk6XZYzPHDP4RSQEmOtu73/K+yUZ4x3bC8t5ZE4Ws1fuoHNsJFOvG8KYfh2s160JOscMflWtFZE6EYlR1SJfFGVMY6qoruVfX23ghYU5qMIdo3vxm7O7ExFmg6KY4NTQpp5SXO3884Gy/RNVdZJXqjKmEagq8zN38dDsTLbuKeei/h2476IUurS2XrcmuDU0+Ge4L8b4hZy8Uh6clclXa/Pp1b4F7/zqNEb0aON0WcY0CQ09ZcPrIhIJJLgHSDemSSqpqObZz9fx6n83ERkewuRxfbh+eDfCQqzXrTH7NfR8/OOAKUA4kCQig4AHVfUSL9ZmTIPV1SkzftzGY3OzKSir5OrUrtx1QW/atGjudGnGNDkNbepJA4YBC8E1WLqIdPdSTcYclxVbC5mcnsHyrYUMTojllZtSGdg11umyjGmyGhr81apaVO+wtzov1GNMg+0ureSJeWv4YOlW4qOb84+rBnL54M7W69aYY2ho8GeIyLVAiIj0BCYB33qvLGOOrLq2jjcWbebpz9ZSXlXLr8/szm0je9AywnrdGtMQDQ3+24C/AJXAO8AnwMPeKsqYI/lvzm7S0jNYl1fKWb3a8rexfejRroXTZRnjV451Pv4I4LdAD2AVcLqq1viiMGM8bd2zj0dmZzEvYycJcVH868ZURqe0s163xpyAY23xvw5UA18DFwIpwO1ersmYAyqqa5m6cD0vfrmeZiLcdX4vfnWm9bo15mQcK/j7qGp/ABF5Bfje+yUZ4+p1O2/1Th6encW2wnLGDujIfRel0Ck20unSjPF7xwr+6v03VLXGflYbX1i7q4QHZmbw35wCkju05L2JwxnePd7psowJGMcK/oEiUuy+LUCk+74AqqqtvFqdCSpF5dU8/dla3li0mRbNQ3nw0r5cOyyBUOt1a0yjOtbQi9aQaryurk7599KtPD5vDXv2VXHtsAT+dH5v4qLDnS7NmIDU0MM5G537PP9LgG2qOtapOoyzlm3ZS1p6Bitzi0jt1prXLxlGv84xTpdlTEBzLPhxjeaVBVhzURDKK6ngf+eu4T/LcmnXsjlPXz2ISwd1ssMzjfEBR4JfRLoAFwOPAHc6UYNxRlVNHa99u5FnP8+hsqaWW885hd+f24MWzZ3cBjEmuDj1bXsauBs44kCnIjIRmAiQkJDgm6qMV325Np8HZmawIb+MkcntuH9sH5LaRDtdljFBx+fBLyJjgTxVXSoi5xxpPlWdBkwDSE1NVd9UZ7xhS8E+HpqdyfzMXSTGRzH95lRGJrd3uixjgpYTW/xnAJeIyEVABNBKRN5S1esdqMV40b6qGv75xXqmfb2B0GbC/4xJ5pc/S6R5qB0sZoyTfB78qnovcC+Ae4v/Lgv9wKKqzFq5g0fnZLGjqILLBnXi3otSaN8qwunSjDE4e1SPCUBZO4pJS8/gu4176NOxFc+OH8ypiXFOl2WM8eBo8KvqQtyjehn/Vriviifnr+WtxZuJiQzjkcv7cc2pCYTYoCjGNDm2xW9OSm2d8t4PW5jyyRqKyqu5fng37jyvF7FR1uvWmKbKgt+csCWb9jA5PYOM7cWclhRH2iV9Selo/fGMaeos+M1x21lUwWNzs/h4+XY6xkTw3PjBjB3Q0XrdGuMnLPhNg1XW1DL9m008t2AdNXXKbSN7cOs5pxAVbv9GxvgT+8aaBlmQvYsHZ2ayqWAf5/Vpz/0X9yEhPsrpsowxJ8CC3xzVxt1lPDQrkwXZeXRvG83rvxzG2b3aOl2WMeYkWPCbwyqrrOH5L3J45euNhIc24y8XpXDTiETCQ21QFGP8nQW/OYSqkr5iO4/OyWJXcSU/H9KF/xnTm3bW69aYgGHBbw5Yva2ItPQMlmzey4AuMUy9fihDElo7XZYxppFZ8Bv2lFUx5dM1vPv9FuKiwvnfn/fnqqFdaWa9bo0JSBb8Qaymto53vt/CPz5dS2llDTePSOT20b2IiQxzujRjjBdZ8AepxRsKSEvPIHtnCSNOiSftkr70an/EcXGMMQHEgj/IbC8s5+9zs5m5YjudYyN58fohXNC3g/W6NSaIWPAHiYrqWl7+egMvfLGeOlVuH92T35x1CpHhNiiKMcHGgj/AqSqfZeXx0KxMtuzZx5i+HfjLxSl0jbNet8YEKwv+AJaTV8qDszL5am0+Pdu14K1bTuNnPds4XZYxxmEW/AGopKKa5xbkMP2bjUSGh/C3sX244fRuhIVYr1tjjAV/QKmrU2b8uI3H5mZTUFbJL4Z25c9jetOmRXOnSzPGNCEW/AFiZW4hk9Mz+HFLIYO6xvLKTakM7BrrdFnGmCbIgt/P7S6t5Il5a/hg6Vbio5sz5aqBXDG4s/W6NcYckQW/n6qureOtxZt5cv5ayqtq+dXPkpg0qictI6zXrTHm6Cz4/dC3ObtJm5nB2l2lnNmzDZPH9aVHuxZOl2WM8RMW/H4kd+8+HpmdxdzVO+kaF8m0G4ZyXp/21uvWGHNcLPj9QEV1LS9+uZ6pC9cjAn86rxe/Pqs7EWHW69YYc/ws+JswVeWTjJ08NCuLbYXljB3QkfsuSqFTbKTTpRlj/JgFfxO1dlcJD8zM4L85BSR3aMl7E4czvHu802UZYwKABX8TU1RezTOfreP1RZuIDg/hgUv6ct1pCYRar1tjTCOx4G8i6uqUfy/dyuPz1rBnXxXjhyVw1/m9iYsOd7o0Y0yAseBvAn7cspe09AxW5BYxtFtrXr9kGP06xzhdljEmQFnwOyivpILH563hw6W5tGvZnKevHsSlgzrZ4ZnGGK+y4HdAVU0dr3+7iWc+X0dlTS2/PfsU/jCyBy2a25/DGON9Pk8aEekKvAG0BxSYpqrP+LoOp3y1Np8HZmawPr+Mc3u35W/j+pLUJtrpsowxQcSJTcwa4E+qukxEWgJLRWS+qmY6UIvPbCnYx0OzM5mfuYvE+Cim35zKyOT2TpdljAlCPg9+Vd0B7HDfLhGRLKAzEJDBv6+qhqkL1/PSVxsIbSbcPaY3t/wsieah1uvWGOMMRxuVRSQRGAx8d5jHJgITARISEnxbWCNQVWav2sGjs7PYXlTBpYM6ce+FKXSIiXC6NGNMkHMs+EWkBfAf4HZVLa7/uKpOA6YBpKamqo/LOynZO4tJS89g8YY99OnYimfGD+bUxDinyzLGGMCh4BeRMFyh/7aqznCiBm8o3FfFU/PX8ubizbSKDOPhy/oxflgCITYoijGmCXHiqB4BXgGyVPVJX7+/N9TWKe//sJUnPsmmqLya64d3487zehEbZb1ujTFNjxNb/GcANwCrRGS5e9p9qjrHgVpO2pJNe5icnkHG9mKGJcWRNq4vfTq1crosY4w5IieO6vkG8Pu2j13FFTw2N5uPftxGh1YRPDt+MOMGdLRet8aYJs+6ih6nyppapn+ziecWrKOmVvnDuT343bmnEBVui9IY4x8srY7DF9l5PDgrk427yxid0p77x6bQLd563Rpj/IsFfwNs2l3Gg7MyWZCdR/c20bw24VTO6d3O6bKMMeaEWPAfRVllDc9/kcMrX28kLES476Jkbh6RRHioDYpijPFfFvyHoaqkr9jOo3Oy2FVcyRVDOnPPmGTatbJet8YY/2fBX0/G9iLS0jP4YdNe+neO4Z/XDWVot9ZOl2WMMY3Ggt9tb1kVUz5dw7vfbyE2KpzHrujPL1K70sx63RpjAkzQB39NbR3vfr+FKZ+upbSyhhtPT+SO0b2IiQpzujRjjPGKoA7+xRsKSEvPIHtnCad3jyftkr707tDS6bKMMcargjL4txeW8/e52cxcsZ3OsZH887ohXNivg/W6NcYEhaAK/orqWl7+egMvfLGeOlX+OKonvz37FCLDbVAUY0zwCIrgV1U+y8rjoVmZbNmzjzF9O/CXi1PoGhfldGnGGONzAR/86/NLeXBmJl+uzadHuxa8dctp/KxnG6fLMsYYxwR08D/xSTYvfbmByLAQ7h/bhxtP70ZYiPW6NcYEt4AO/po65Yohnbl7TDJtWjR3uhxjjGkSAjr47xmTbEfqGGNMPQHd7mGhb4wxPxXQwW+MMeanLPiNMSbIWPAbY0yQseA3xpggY8FvjDFBxoLfGGOCjAW/McYEGQt+Y4wJMhb8xhgTZAL6lA3GmKOoKIK8bMjPgrwsqCyF0OYQFgmhERAWAaGR9aa5rz0fD4vwmOZ+3HrNN2kW/MFAFWqroa7G9cW0L2VwqS6H/DWucM/LdF9nQXHuwXnCoiEy1jVvTYXrGj3x9wyNcK0wDqwYGroCiYQW7aB1N4jtBjFdIMTGv25sFvyqUFcLWlvvuu4Y0+vqPVb/fv3pNVBb5Qrg2mqP21VQV3/a/ttVHs+rglrP29Xu5x3mNevqv37Nwc8bGgEtO0DLTtCqI7R0X1p1PHRaqJ3N1O/UVkNBzqHhnpcFezZwIMRDwqFNb+g2AtqlQLs+ruuYrtDMo+V3/8ZCTTlUV7hWBvtXCAeuKz0ed99vyONVpVC2+6evWVNx6P8qgDSDVp1dK4HW3SA2weN2N9f/arMAbLFWhcoSKMt3feZGXvkFdvD/59ewfoEreLXu8OF8Mls1jU5cX8yQcNcfOiTs4O1mHrf3X4dFuG43C23Y85qFwL4CKN4BJTtg2zLXdU3FT0uJivdYEXiuKDyuo+Ls14MT6uqgcNNPt+B3r3Ot9MEVmPE9oH1f6H/VwZCP6w4hDfjai0BouOsSEePVj3OImirX/2ThZijcAns3u27v3ez6LpfsOHT+kHDXrwLPlcH+69huEN2m6fyP1tVC+V4ozYOyPNfKrzTPFe5leVCa777tvuz/Xv5hKbTp0ailBHbwdzkVmrcACXF9EZp5XofUuz7e6XKYaSGurY/DTQ9xh3Mzz2AOPzg9JNw1r6+pQkWhe2Ww/eBKoXj7wevty13/iPVXkiHN3SuFw/xiaNXp4K+JsAjff65AoOpa/p4Bn5/larap3ndwvtgEV6j3uuDgFnx8T/9c7qHhruBu3e3wj1dXQFGua8W3f6WwfwWRNdO1YeMpLNr9KyHhMCuGBFfz1smoqXR9N0rdQV7mDvLS/Hq382HfbtcGaH0SAtFtoUVbiG4HbXq5b7vvR8efXI2HIaq+3+IVkTHAM0AI8LKqPna0+VNTU3XJkiU+qc0cQW01lOz86UqhZMfBlUXJjkMDab/I1vWaljq4mpL2rwSbhblWgAfuh3pMd/9SafC8Hvf3r6D9Qdluj+YZj634yqKD87TocGjzTLsUaNsbmrd0ru6mprLEtSKo/2th/3VVyaHzR8T89FdC626uDZeqMo8t8nyPgM8/GOiefx9PYVHu4G7r2mdxyO02rkDfPz0i1mvNVSKyVFVTfzLd18EvIiHAWuA8IBf4ARivqplHeo4Fv59QdR0p8pOVwvZDVw6lefisie1oK4xmoY20YjjJ1yjf4/5F5RYR62qiaZt8aNBHxZ3c+wQ7VVdTi+fKwHMFUbjl8M2e+0W2PrgVfsgWeZufhnt4tO8+11EcKfidaOoZBuSo6gYAEXkPuBQ4YvAbPyHi+ukcGesKqiOpq3PtxNu/U7uuxmOndP37nvPVv19zlHkb8Jr1dySeiMbYcGrewmMrvg+0aO8/v1T8iYhr5RkVB50G//TxujpX80zhFijeBuEtDza/RMW7mqEChBPB3xnY6nE/Fzit/kwiMhGYCJCQkOCbyoxvNGsGzcKBwPkimQDQrJl7n1UHpyvxuiZ7HJSqTlPVVFVNbdu2rdPlGGNMwHAi+LcBXT3ud3FPM8YY4wNOBP8PQE8RSRKRcOAaIN2BOowxJij5vI1fVWtE5A/AJ7gO55yuqhm+rsMYY4KVIx24VHUOMMeJ9zbGmGDXZHfuGmOM8Q4LfmOMCTIW/MYYE2QcOVfP8RKRfGDzCT69DbC7Ecvxd7Y8DrJlcShbHocKhOXRTVV/0hHKL4L/ZIjIksOdqyJY2fI4yJbFoWx5HCqQl4c19RhjTJCx4DfGmCATDME/zekCmhhbHgfZsjiULY9DBezyCPg2fmOMMYcKhi1+Y4wxHiz4jTEmyAR08IvIGBFZIyI5InKP0/U4RUS6isgXIpIpIhki8kena2oKRCRERH4UkVlO1+I0EYkVkQ9FJFtEskTkdKdrcoqI3OH+nqwWkXdFxA9HrT+6gA1+99i+LwAXAn2A8SLSx9mqHFMD/ElV+wDDgd8H8bLw9Ecgy+kimohngHmqmgwMJEiXi4h0BiYBqaraD9cZhK9xtqrGF7DBj8fYvqpaBewf2zfoqOoOVV3mvl2C60vd2dmqnCUiXYCLgZedrsVpIhIDnAW8AqCqVapa6GhRzgoFIkUkFIgCtjtcT6ML5OA/3Ni+QR12ACKSCAwGvnO4FKc9DdwN1DlcR1OQBOQDr7qbvl4WkWini3KCqm4DpgBbgB1Akap+6mxVjS+Qg9/UIyItgP8At6tqsdP1OEVExgJ5qrrU6VqaiFBgCDBVVQcDZUBQ7hMTkda4WgaSgE5AtIhc72xVjS+Qg9/G9vUgImG4Qv9tVZ3hdD0OOwO4REQ24WoCHCkibzlbkqNygVxV3f8r8ENcK4JgNBrYqKr5qloNzABGOFxTowvk4Lexfd1ERHC132ap6pNO1+M0Vb1XVbuoaiKu/4sFqhpwW3UNpao7ga0i0ts9aRSQ6WBJTtoCDBeRKPf3ZhQBuKPbkaEXfcHG9j3EGcANwCoRWe6edp97CExjAG4D3nZvJG0AJjhcjyNU9TsR+RBYhutouB8JwFM32CkbjDEmyARyU48xxpjDsOA3xpggY8FvjDFBxoLfGGOCjAW/McYEGQt+Y9xEpJmIzBORBKdrMcab7HBOY9xE5BSgi6p+6XQtxniTBb8xgIjUAqs8Jr2nqo85VY8x3mTBbwwgIqWq2sLpOozxBWvjN+YoRGSTiDwuIqtE5HsR6eGenigiC0RkpYh8vn+/gIi0F5GPRGSF+zLCPf1jEVnqHtlpopOfyRgLfmNcIkVkucflao/HilS1P/A8rvP4AzwHvK6qA4C3gWfd058FvlTVgbjOcLn//FC/VNWhQCowSUTivfx5jDkia+oxhiM39bhP3TxSVTe4T229U1XjRWQ30FFVq93Td6hqGxHJx7WDuLLe66QBl7vvJgIXqOpiL34kY44oYM/OaUwj0iPcbhAROQfXed5PV9V9IrIQCLgBvI3/sKYeY47tao/rRe7b33JwEO7rgK/dtz8HbgUQkRD3eLYxwF536CfjGvDeGMdYU48xHPZwznmqeo+7qed94EKgEhivqjki0g14FWiDa7zaCaq6RUTa4zp/e3egFtdKYBnwMa4mnjVALJCmqgu9/sGMOQwLfmOOwh38qaq62+lajGks1tRjjDFBxrb4jTEmyNgWvzHGBBkLfmOMCTIW/MYYE2Qs+I0xJshY8BtjTJD5f3/iPFT1YY5PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt_epoch = [10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]\n",
    "plt_epoch = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "plt_loss = [0.2028, 0.2224, 0.2604, 0.0816, 0.0487, 0.0483, 0.3402, 0.2819, 0.0639, 0.2141]\n",
    "\n",
    "plt.plot(plt_epoch)\n",
    "plt.plot(plt_loss)\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Perda')\n",
    "plt.title('Gráfico de Perdas')\n",
    "plt.legend(labels=['Época', 'Perda'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f2c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação (Conjunto de Validação):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.52      0.59      0.55       109\n",
      "           2       0.81      0.76      0.78       246\n",
      "\n",
      "    accuracy                           0.71       358\n",
      "   macro avg       0.66      0.67      0.67       358\n",
      "weighted avg       0.72      0.71      0.71       358\n",
      "\n",
      "Relatório de Classificação (Conjunto de Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.47      0.56      0.51       108\n",
      "           2       0.79      0.73      0.76       247\n",
      "\n",
      "    accuracy                           0.67       358\n",
      "   macro avg       0.59      0.54      0.56       358\n",
      "weighted avg       0.69      0.67      0.68       358\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cadu\\AppData\\Local\\Temp\\ipykernel_10312\\312785182.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.fc4(x))\n",
      "C:\\Users\\cadu\\AppData\\Local\\Temp\\ipykernel_10312\\312785182.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.fc4(x))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "# Previsões no conjunto de validação\n",
    "val_labels, val_predictions = predict(model, val_loader)\n",
    "print(\"Relatório de Classificação (Conjunto de Validação):\")\n",
    "print(classification_report(val_labels, val_predictions))\n",
    "\n",
    "# Previsões no conjunto de teste\n",
    "test_labels, test_predictions = predict(model, test_loader)\n",
    "print(\"Relatório de Classificação (Conjunto de Teste):\")\n",
    "print(classification_report(test_labels, test_predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db22fae",
   "metadata": {},
   "source": [
    "### Discussão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f20057d7",
   "metadata": {},
   "source": [
    "A análise das métricas de avaliação, como precisão, recall, f1-score e acurácia, fornece insights sobre o desempenho do modelo em diferentes classes ou categorias.\n",
    "\n",
    "Com base no resultado do nosso treinamento e analisando o relatório de classificação, segue discussões:\n",
    "\n",
    "A precisão média ponderada (weighted avg) é de 71% no conjunto de validação e 68% no conjunto de teste. Isso indica que o modelo está realizando uma classificação razoável, mas ainda há espaço para melhorias. A classe \"2\" (maior popularidade) parece ter um desempenho melhor do que as outras classes, sugerindo que o modelo pode ter dificuldade em distinguir entre as classes de popularidade mais baixa.\n",
    "O PyTorch oferece vários recursos e flexibilidade para enfrentar problemas de classificação de dados do mundo real. É necessário considerar cuidadosamente a qualidade dos dados, experimentar diferentes abordagens e ajustar os hiperparâmetros para obter resultados cada vez melhores. É possível construir modelos eficazes e obter insights valiosos por meio da classificação de dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
